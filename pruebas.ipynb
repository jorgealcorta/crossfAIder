{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# crossfAIder - pruebas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Extract features for A and B using VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try using Encodec by facebook https://huggingface.co/docs/transformers/model_doc/encodec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azict\\anaconda3\\envs\\crossfaider_env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "from transformers import EncodecModel, AutoProcessor\n",
    "import numpy as np\n",
    "import IPython\n",
    "import torchaudio.transforms as T\n",
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Pretrained Encodec model capable of extracting audio features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azict\\anaconda3\\envs\\crossfaider_env\\Lib\\site-packages\\transformers\\models\\encodec\\modeling_encodec.py:124: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.register_buffer(\"padding_total\", torch.tensor(kernel_size - stride, dtype=torch.int64), persistent=False)\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.48, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    }
   ],
   "source": [
    "# Load the EnCodec model\n",
    "model = EncodecModel.from_pretrained(\"facebook/encodec_24khz\")\n",
    "processor = AutoProcessor.from_pretrained(\"facebook/encodec_24khz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_encodec_features(audio_path, duration=5, last=True):\n",
    "    \"\"\"\n",
    "    Extract EnCodec latent features from an MP3 file.\n",
    "    \n",
    "    Args:\n",
    "        audio_path (str): Path to the MP3 file.\n",
    "        duration (float): Duration of the extracted segment in seconds (default: 5s).\n",
    "        last (bool): If True, extracts the last `duration` seconds. If False, extracts the first `duration` seconds.\n",
    "\n",
    "    Returns:\n",
    "        Tensor: Encoded audio_codes (latent representation).\n",
    "    \"\"\"\n",
    "    # Load MP3 file using pydub\n",
    "    audio = AudioSegment.from_mp3(audio_path)\n",
    "\n",
    "    # Determine start time\n",
    "    start_time = (audio.duration_seconds - duration) if last else 0  # Last X seconds or first X seconds\n",
    "\n",
    "    # Extract the required segment\n",
    "    segment = audio[start_time * 1000 : (start_time + duration) * 1000]  # Convert to milliseconds\n",
    "\n",
    "    # Convert to MONO\n",
    "    segment = segment.set_channels(1)\n",
    "\n",
    "    # Convert to waveform tensor\n",
    "    samples = torch.tensor(segment.get_array_of_samples()).float()\n",
    "    waveform = samples / (2**15)  # Normalize (convert int16 to float)\n",
    "\n",
    "    # Ensure correct shape for EnCodec: (1, samples) instead of (samples, 1, 1)\n",
    "    waveform = waveform.unsqueeze(0)  # Add batch dimension → Shape (1, samples)\n",
    "\n",
    "    # Resample to EnCodec’s required sample rate (24 kHz)\n",
    "    waveform = T.Resample(orig_freq=audio.frame_rate, new_freq=processor.sampling_rate)(waveform)\n",
    "\n",
    "    # Ensure correct shape: (channels, samples) → EnCodec expects (1, samples)\n",
    "    waveform = waveform.squeeze(0)  # Remove batch dim → Now shape (1, samples)\n",
    "\n",
    "    # Prepare for EnCodec\n",
    "    inputs = processor(raw_audio=waveform, sampling_rate=processor.sampling_rate, return_tensors=\"pt\")\n",
    "\n",
    "    # Encode to latent space\n",
    "    with torch.no_grad():\n",
    "        encoder_outputs = model.encode(inputs[\"input_values\"], inputs[\"padding_mask\"])\n",
    "\n",
    "    return encoder_outputs.audio_codes  # Return only the audio codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define an interpolation function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO try alternatives to Linear Interpolation:\n",
    "\n",
    "Spherical Interpolation (SLERP): More natural blending in latent space.\n",
    "\n",
    "Bezier Curves: Non-linear transitions for smoother effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def interpolate_encodec_features(audio_codes_A, audio_codes_B, steps=10):\n",
    "    \"\"\"Interpolates between two sets of EnCodec latent representations.\"\"\"\n",
    "    interpolations = []\n",
    "    \n",
    "    for alpha in np.linspace(0, 1, steps):\n",
    "        # Linear interpolation in latent space\n",
    "        interpolated_code = (1 - alpha) * audio_codes_A + alpha * audio_codes_B\n",
    "        interpolations.append(interpolated_code)\n",
    "    \n",
    "    # Stack tensors into a single batch tensor\n",
    "    return torch.stack(interpolations)  # Now it's a single tensor instead of a list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decode back to waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_encodec_features(interpolated_codes):\n",
    "    \"\"\"Decodes EnCodec latent codes into audio waveforms.\"\"\"\n",
    "    \n",
    "    if not isinstance(interpolated_codes, torch.Tensor):\n",
    "        raise ValueError(f\"Expected torch.Tensor but got {type(interpolated_codes)}\")\n",
    "\n",
    "    # Ensure correct batch processing\n",
    "    interpolated_audio = []\n",
    "    \n",
    "    for i in range(interpolated_codes.shape[0]):  # Loop through batch dimension\n",
    "        with torch.no_grad():\n",
    "            decoded_audio = model.decode(audio_codes=interpolated_codes[i].unsqueeze(0),\n",
    "                                         audio_scales=None, padding_mask=None)\n",
    "        \n",
    "        interpolated_audio.append(decoded_audio.squeeze().cpu().numpy())\n",
    "\n",
    "    return interpolated_audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save output as mp3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "import soundfile as sf\n",
    "\n",
    "def save_as_mp3(audio_data, output_path, sr=24000):\n",
    "    \"\"\"Saves an array of audio samples as an MP3 file.\"\"\"\n",
    "    # Convert numpy array to WAV file first\n",
    "    temp_wav = \"temp_transition.wav\"\n",
    "    sf.write(temp_wav, audio_data, sr)\n",
    "    \n",
    "    # Convert WAV to MP3 using pydub\n",
    "    sound = AudioSegment.from_wav(temp_wav)\n",
    "    sound.export(output_path, format=\"mp3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run full process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract last 5 seconds of Track A\n",
    "trackA_codes = extract_encodec_features(\"./tracks/trackA.mp3\", duration=5, last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 62,  62,  62,  62, 408, 408, 408, 408, 408, 408, 408, 408,  62,  62,\n",
      "            62,  62,  62,  62,  62,  62,  62,  62,  62,  62,  62,  62,  62,  62,\n",
      "           408, 408,  62,  62,  62,  62,  62,  62,  62,  62,  62,  62,  62,  62,\n",
      "            62,  62,  62,  62,  62,  62,  62,  62,  62,  62,  62,  62,  62,  62,\n",
      "            62,  62,  62,  62,  62,  62,  62,  62,  62,  62,  62,  62,  62,  62,\n",
      "            62,  62,  62,  62,  62,  62,  62,  62,  62,  62,  62,  62,  62,  62,\n",
      "            62,  62,  62,  62,  62,  62,  62,  62,  62,  62,  62,  62,  62,  62,\n",
      "            62,  62,  62,  62,  62,  62,  62,  62,  62,  62,  62,  62,  62,  62,\n",
      "            62,  62,  62,  62,  62,  62,  62,  62,  62,  62,  62,  62,  62,  62,\n",
      "            62,  62,  62,  62,  62,  62,  62,  62,  62,  62,  62,  62,  62,  62,\n",
      "            62,  62,  62,  62,  62,  62,  62,  62,  62,  62,  62,  62,  62,  62,\n",
      "            62,  62,  62,  62,  62,  62,  62,  62,  62,  62,  62,  62,  62,  62,\n",
      "            62,  62,  62,  62,  62,  62,  62,  62,  62,  62,  62,  62,  62,  62,\n",
      "            62,  62,  62,  62,  62,  62,  62,  62,  62,  62,  62,  62,  62,  62,\n",
      "            62,  62,  62,  62,  62,  62,  62,  62,  62,  62,  62,  62,  62,  62,\n",
      "            62,  62,  62,  62,  62,  62,  62,  62,  62,  62,  62,  62,  62,  62,\n",
      "            62,  62,  62,  62,  62,  62,  62,  62,  62,  62,  62,  62,  62,  62,\n",
      "            62,  62,  62,  62,  62,  62,  62,  62,  62,  62,  62,  62,  62,  62,\n",
      "            62,  62,  62,  62,  62,  62,  62,  62,  62,  62,  62,  62,  62,  62,\n",
      "            62,  62,  62,  62,  62,  62,  62,  62,  62,  62,  62,  62,  62,  62,\n",
      "            62,  62,  62,  62,  62,  62,  62,  62,  62,  62,  62,  62,  62,  62,\n",
      "            62,  62,  62,  62,  62,  62,  62,  62,  62,  62,  62,  62,  62,  62,\n",
      "            62,  62,  62,  62,  62,  62,  62,  62,  62,  62,  62,  62,  62,  62,\n",
      "            62,  62,  62,  62,  62,  62,  62,  62,  62,  62,  62,  62,  62,  62,\n",
      "            62,  62,  62,  62,  62,  62,  62,  62,  62,  62,  62,  62,  62,  62,\n",
      "            62,  62,  62,  62,  62,  62,  62,  62,  62,  62,  62,  62,  62,  62,\n",
      "            62,  62,  62,  62,  62,  62,  62,  62,  62,  62,  62],\n",
      "          [913, 424, 424, 424, 544, 544, 913, 913, 913, 913, 913, 913, 424, 424,\n",
      "           424, 424, 424, 424, 424, 424, 424, 424, 424, 424, 424, 424, 424, 424,\n",
      "           913, 913, 424, 424, 424, 424, 424, 424, 518, 424, 424, 424, 424, 424,\n",
      "           424, 424, 424, 424, 424, 424, 424, 424, 424, 424, 424, 424, 424, 424,\n",
      "           424, 518, 424, 424, 518, 424, 424, 518, 424, 424, 518, 424, 518, 518,\n",
      "           518, 518, 518, 518, 518, 518, 518, 518, 518, 518, 518, 518, 518, 518,\n",
      "           518, 518, 424, 518, 518, 518, 518, 518, 518, 518, 518, 518, 518, 518,\n",
      "           518, 518, 518, 518, 518, 518, 518, 518, 518, 518, 518, 518, 518, 518,\n",
      "           518, 518, 518, 518, 518, 518, 518, 518, 518, 518, 518, 518, 518, 518,\n",
      "           518, 518, 518, 518, 518, 518, 518, 518, 518, 518, 518, 518, 518, 518,\n",
      "           518, 518, 518, 518, 518, 518, 518, 518, 518, 518, 518, 518, 518, 518,\n",
      "           518, 518, 518, 518, 518, 518, 518, 518, 518, 518, 518, 518, 518, 518,\n",
      "           518, 518, 518, 518, 518, 518, 518, 518, 518, 518, 518, 518, 518, 518,\n",
      "           518, 518, 518, 518, 518, 518, 518, 518, 518, 518, 518, 518, 518, 518,\n",
      "           518, 518, 518, 518, 518, 518, 518, 518, 518, 518, 518, 518, 518, 518,\n",
      "           518, 518, 518, 518, 518, 518, 518, 518, 518, 518, 518, 518, 518, 518,\n",
      "           518, 518, 518, 518, 518, 518, 518, 518, 518, 518, 518, 518, 518, 518,\n",
      "           518, 518, 518, 518, 518, 518, 518, 518, 518, 518, 518, 518, 518, 518,\n",
      "           518, 518, 518, 518, 518, 518, 518, 518, 518, 518, 518, 518, 518, 518,\n",
      "           518, 518, 518, 518, 518, 518, 518, 518, 518, 518, 518, 518, 518, 518,\n",
      "           518, 518, 518, 518, 518, 518, 518, 518, 518, 518, 518, 518, 518, 518,\n",
      "           518, 518, 518, 518, 518, 518, 518, 518, 518, 518, 518, 518, 518, 518,\n",
      "           518, 518, 518, 518, 518, 518, 518, 518, 518, 518, 518, 518, 518, 518,\n",
      "           518, 518, 518, 518, 518, 518, 518, 518, 518, 518, 518, 518, 518, 518,\n",
      "           518, 518, 518, 518, 518, 518, 518, 518, 518, 518, 518, 518, 518, 518,\n",
      "           518, 518, 518, 518, 518, 518, 518, 518, 518, 518, 518, 518, 518, 518,\n",
      "           518, 518, 518, 518, 518, 518, 518, 518, 518, 518, 518]]]])\n"
     ]
    }
   ],
   "source": [
    "print(trackA_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract first 5 seconds of Track B\n",
    "trackB_codes = extract_encodec_features(\"./tracks/trackB.mp3\", duration=5, last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 862,  293,  868,  651,  967,  136,  275,  255,  868,  321,  967,\n",
      "            811,  862,  293,  131,  565,  670,  811,  325,  293,  670,  696,\n",
      "             73,  696,   80,   73,  293,  670,  696,  457,  811,   80,  875,\n",
      "            293,  756,  811,  875,  811,  310,  131,  991,  131,  457,  900,\n",
      "             80,  670,  957,  670,  131,  321,  696,  293,  753,  293,  900,\n",
      "            131,   52,  811,   91,  879,  310,  875,  321,  325, 1022,  879,\n",
      "            971,  604,  875,  699,  904,  491,  310,  228,  370,  228,  224,\n",
      "            228,  879,  310,  604,   52,  699,  724,  228,  724,  629,  999,\n",
      "            904,  604,  879,  904,  325,  228,  432,  904,  430,  432,  834,\n",
      "            904,  904,  724,  904,  432, 1017,  604,  257,  834,  430,  257,\n",
      "            724,  228,  430,  834,  724,  432,  855,  855, 1019,  855, 1019,\n",
      "            430, 1017,  855, 1017, 1019,  257,  106,  855, 1017,  106,  855,\n",
      "            876, 1019, 1017,  855, 1019,  855,  876,  876,  430, 1019,  855,\n",
      "           1019,  876, 1017,  876, 1017,  738, 1017, 1019,  106,  876,  876,\n",
      "           1019,  876,  738, 1019,  738,  876,  408, 1019,  738, 1019,  408,\n",
      "           1017,  876,  738,  738,  876,  738,  738,  876,  738,  738,  738,\n",
      "            738,  408,  738,  738,  738,  738,  738,  738,  408,  738,  408,\n",
      "            738,  738,  408,  738,  408,  738,  408,  408,  408,  408,  738,\n",
      "            738,  738,  408,  738,  408,  408,  408,  408,  408,  408,  408,\n",
      "            408,  408,  408,   62,  408,  408,  408,  408,  408,  408,   62,\n",
      "            408,  408,  408,  408,   62,   62,  408,   62,   62,   62,   62,\n",
      "             62,  408,  408,  408,  408,  408,   62,  408,  408,  408,   62,\n",
      "            408,  408,  408,   62,   62,  408,   62,   62,   62,  408,  408,\n",
      "             62,   62,   62,   62,   62,   62,   62,   62,   62,   62,   62,\n",
      "             62,   62,   62,   62,   62,   62,   62,   62,   62,   62,   62,\n",
      "             62,   62,   62,   62,   62,   62,   62,   62,   62,   62,   62,\n",
      "             62,   62,   62,   62,   62,   62,   62,   62,   62,   62,   62,\n",
      "             62,   62,   62,   62,   62,   62,   62,   62,   62,   62,   62,\n",
      "             62,   62,   62,   62,   62,   62,   62,   62,   62,   62,   62,\n",
      "             62,   62,   62,   62,   62,   62,   62,   62,   62,   62,   62,\n",
      "             62,   62,   62,   62,   62,   62,   62,   62,   62,   62,   62,\n",
      "             62,   62,   62,   62,   62,   62,   62,   62,   62,   62,   62,\n",
      "             62,   62,   62,   62,   62,   62,   62,   62,   62,   62,   62,\n",
      "             62,   62,   62,   62,   62,   62,   62,   62,   62,   62,   62,\n",
      "             62],\n",
      "          [ 307,  220,  692,  355,  826,  980,  916,  692,  204,  829,  236,\n",
      "            583,  298, 1021,  282,  299, 1002,  941,  969,  596,  266,  487,\n",
      "            821,  916,  601,  516,  959,  571,  436,  849,  564,  228,  928,\n",
      "            723, 1002,  975,  891,  266,  877,  282,  984,  419,  841,  282,\n",
      "            835,  959,  924,  564,  835,  841,  646,  564,  496,  102,  601,\n",
      "            821,  571,  655,  601,  741,  877,  961,  729,  700,  564,  404,\n",
      "            916,  877,  646,  835,  700,  835,  841,  404,  859,  765,  646,\n",
      "            430,  436,  937,  363,  942,  363,  829,  601,  404,  740,  419,\n",
      "            571,  404,  646,  419,  483,  363,  266,  516,  877,  942,  835,\n",
      "            601,  601,  700,  363,  114,  928,  928,  765,  859,  841,  363,\n",
      "            913,  601,  646,  937,  363,  928,  913,  404,  419,  841,  937,\n",
      "            700,  424,  841,  913,  765,  841,  363,  913,  404,  424,  363,\n",
      "            544,  404,  765,  913,  601,  700,  765,  829,  841,  646,  404,\n",
      "            765,  544,  913,  404,  913,  859,  913,  913,  841,  765,  841,\n",
      "            518,  765,  937,  841,  937,  765,  424,  601,  571,  404,  424,\n",
      "            765,  518,  700,  765,  765,  700,  937,  404,  544,  601,  913,\n",
      "            404,  424,  765,  518,  700,  765,  518,  700,  424,  765,  424,\n",
      "            544,  404,  404,  601,  424,  404,  424,  424,  424,  518,  765,\n",
      "            841,  700,  424,  765,  424,  518,  424,  518,  518,  518,  518,\n",
      "            913,  913,  518,  424,  518,  913,  518,  518,  913,  913,  424,\n",
      "            518,  913,  913,  518,  424,  424,  518,  424,  424,  424,  424,\n",
      "            424,  518,  913,  913,  913,  913,  424,  518,  913,  913,  424,\n",
      "            518,  518,  913,  424,  424,  913,  424,  424,  424,  913,  913,\n",
      "            424,  424,  424,  424,  424,  518,  424,  424,  518,  424,  424,\n",
      "            424,  424,  424,  424,  424,  424,  424,  518,  424,  424,  424,\n",
      "            424,  424,  424,  424,  424,  518,  424,  424,  518,  518,  424,\n",
      "            518,  518,  518,  518,  424,  518,  518,  518,  518,  518,  518,\n",
      "            518,  518,  518,  518,  518,  518,  518,  518,  518,  518,  518,\n",
      "            518,  518,  518,  518,  518,  518,  518,  518,  518,  518,  518,\n",
      "            518,  518,  518,  518,  518,  518,  518,  518,  518,  518,  518,\n",
      "            518,  518,  518,  518,  518,  518,  518,  518,  518,  518,  518,\n",
      "            518,  518,  518,  518,  518,  518,  518,  518,  518,  518,  518,\n",
      "            518,  518,  518,  518,  518,  518,  518,  518,  518,  518,  518,\n",
      "            518,  518,  518,  518,  518,  518,  518,  518,  518,  518,  518,\n",
      "            518]]]])\n"
     ]
    }
   ],
   "source": [
    "print(trackB_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate interpolated audio codes\n",
    "interpolated_codes = interpolate_encodec_features(trackA_codes, trackB_codes, steps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor([[[[[ 62.0000,  62.0000,  62.0000,  ...,  62.0000,  62.0000,\n",
      "             62.0000],\n",
      "           [913.0000, 424.0000, 424.0000,  ..., 518.0000, 518.0000,\n",
      "            518.0000]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[150.8889,  87.6667, 151.5556,  ...,  62.0000,  62.0000,\n",
      "             62.0000],\n",
      "           [845.6666, 401.3333, 453.7778,  ..., 518.0000, 518.0000,\n",
      "            518.0000]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[239.7778, 113.3333, 241.1111,  ...,  62.0000,  62.0000,\n",
      "             62.0000],\n",
      "           [778.3334, 378.6667, 483.5555,  ..., 518.0000, 518.0000,\n",
      "            518.0000]]]],\n",
      "\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "\n",
      "        [[[[684.2222, 241.6667, 688.8889,  ...,  62.0000,  62.0000,\n",
      "             62.0000],\n",
      "           [441.6667, 265.3333, 632.4445,  ..., 518.0000, 518.0000,\n",
      "            518.0000]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[773.1111, 267.3333, 778.4445,  ...,  62.0000,  62.0000,\n",
      "             62.0000],\n",
      "           [374.3333, 242.6667, 662.2222,  ..., 518.0000, 518.0000,\n",
      "            518.0000]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[862.0000, 293.0000, 868.0000,  ...,  62.0000,  62.0000,\n",
      "             62.0000],\n",
      "           [307.0000, 220.0000, 692.0000,  ..., 518.0000, 518.0000,\n",
      "            518.0000]]]]])\n"
     ]
    }
   ],
   "source": [
    "print(type(interpolated_codes))\n",
    "print(interpolated_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[58]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Convert interpolated features back to audio\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m audio_transitions = \u001b[43mdecode_encodec_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43minterpolated_codes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[57]\u001b[39m\u001b[32m, line 12\u001b[39m, in \u001b[36mdecode_encodec_features\u001b[39m\u001b[34m(interpolated_codes)\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(interpolated_codes.shape[\u001b[32m0\u001b[39m]):  \u001b[38;5;66;03m# Loop through batch dimension\u001b[39;00m\n\u001b[32m     11\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m         decoded_audio = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_codes\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterpolated_codes\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m                                     \u001b[49m\u001b[43maudio_scales\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m     interpolated_audio.append(decoded_audio.squeeze().cpu().numpy())\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m interpolated_audio\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\azict\\anaconda3\\envs\\crossfaider_env\\Lib\\site-packages\\transformers\\models\\encodec\\modeling_encodec.py:747\u001b[39m, in \u001b[36mEncodecModel.decode\u001b[39m\u001b[34m(self, audio_codes, audio_scales, padding_mask, return_dict)\u001b[39m\n\u001b[32m    745\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(audio_codes) != \u001b[32m1\u001b[39m:\n\u001b[32m    746\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExpected one frame, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(audio_codes)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m747\u001b[39m     audio_values = \u001b[38;5;28mself\u001b[39m._decode_frame(audio_codes[\u001b[32m0\u001b[39m], \u001b[43maudio_scales\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[32m    748\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    749\u001b[39m     decoded_frames = []\n",
      "\u001b[31mTypeError\u001b[39m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# Convert interpolated features back to audio\n",
    "audio_transitions = decode_encodec_features(interpolated_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the 5th interpolated step as an MP3 transition file\n",
    "save_as_mp3(audio_transitions[5], \"transition.mp3\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crossfaider_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
